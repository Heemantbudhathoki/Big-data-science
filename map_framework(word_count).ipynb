{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08786b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are doing this in a copy big data ->map frame then this doing practically in a here \n",
    "# mechanical enginerring \n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_PYTHON']='python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18db9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"Word_count\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext #data structure of spark remember it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom pyspark.sql import SparkSession\n",
    "import re\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"Word_count\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext #data structure of spark remember it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1652a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = \"\"\"Apache Spark is a unified analytics engine for big data processing. Spark provides high level APIs in Java, Scale, Pyhon\n",
    "and in R. Spark is designed for fast and easy-to-use machine learning.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d226b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.sql.functions import explode, split, lower, col, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab8fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(text,)], [\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a4bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Apache Spark is a...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = (df\n",
    "           .select(explode(split(lower(col(\"text\")), r\"[\\s\\W]+\")).alias(\"word\"))   # r is a regular express, /s is a space \n",
    "           .filter(col(\"word\") != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1da0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|    apache|\n",
      "|     spark|\n",
      "|        is|\n",
      "|         a|\n",
      "|   unified|\n",
      "| analytics|\n",
      "|    engine|\n",
      "|       for|\n",
      "|       big|\n",
      "|      data|\n",
      "|processing|\n",
      "|     spark|\n",
      "|  provides|\n",
      "|      high|\n",
      "|     level|\n",
      "|      apis|\n",
      "|        in|\n",
      "|      java|\n",
      "|     scale|\n",
      "|     pyhon|\n",
      "+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "word_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f442c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|    spark|    3|\n",
      "|      for|    2|\n",
      "|       in|    2|\n",
      "|       is|    2|\n",
      "|      and|    2|\n",
      "|    scale|    1|\n",
      "|    pyhon|    1|\n",
      "|    level|    1|\n",
      "| provides|    1|\n",
      "|     apis|    1|\n",
      "|  machine|    1|\n",
      "|     fast|    1|\n",
      "| learning|    1|\n",
      "|      use|    1|\n",
      "| designed|    1|\n",
      "|   apache|    1|\n",
      "|     data|    1|\n",
      "|     high|    1|\n",
      "|analytics|    1|\n",
      "|     easy|    1|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "word_count_df = word_df.groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
    "word_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d8ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5ed4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7373e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2 creation of RDDs (Resillient distributed dataset) \n",
    "# ----> it is a immutable\n",
    "\n",
    "rdd = sc.parallelize([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764c2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rdd = rdd.flatMap(lambda line: re.findall(r\"\\b\\w+\\b\", line.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264a8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_rdd = words_rdd.map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888760ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_rdd = pairs_rdd.reduceByKey(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21690bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts = word_counts_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark : 3\n",
      "in : 2\n",
      "for : 2\n",
      "and : 2\n",
      "is : 2\n",
      "apache : 1\n",
      "machine : 1\n",
      "apis : 1\n",
      "level : 1\n",
      "a : 1\n",
      "high : 1\n",
      "fast : 1\n",
      "to : 1\n",
      "analytics : 1\n",
      "easy : 1\n",
      "learning : 1\n",
      "data : 1\n",
      "r : 1\n",
      "java : 1\n",
      "unified : 1\n",
      "engine : 1\n",
      "processing : 1\n",
      "provides : 1\n",
      "designed : 1\n",
      "big : 1\n",
      "pyhon : 1\n",
      "use : 1\n",
      "scale : 1\n"
     ]
    }
   ],
   "source": [
    "for word, count, in sorted_counts.collect():\n",
    "    print(f\"{word} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79ef56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c5b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9216c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
